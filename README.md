FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista
FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista


Nome do grupo
üë®‚Äçüéì Integrante:
Vit√≥rio Paciulo

üë©‚Äçüè´ Professores:

Tutor(a):
Ana Cristina dos Santos

Coordenador(a):
Andr√© Godoi Chiovato

# üåæ Classifica√ß√£o de Gr√£os de Trigo com Aprendizado de M√°quina (Seeds Dataset ‚Äì CRISP-DM)

Este projeto aplica **aprendizado de m√°quina** para classificar **variedades de trigo** a partir de suas **caracter√≠sticas f√≠sicas**, utilizando o famoso **Seeds Dataset** (UCI Machine Learning Repository) e a metodologia **CRISP-DM**.

O contexto √© o de **cooperativas agr√≠colas de pequeno porte**, onde a classifica√ß√£o de gr√£os costuma ser feita de forma **manual**, por especialistas, o que pode ser:

- Demorado  
- Sujeito a erro humano  
- Pouco padronizado entre avaliadores  

A ideia √© mostrar que, com um conjunto de dados relativamente simples e algoritmos cl√°ssicos de ML, √© poss√≠vel **automatizar (ou apoiar) a classifica√ß√£o** com alta acur√°cia.

---

## üéØ Objetivos do Projeto

1. Aplicar a metodologia **CRISP-DM** no problema de classifica√ß√£o de gr√£os.
2. **Analisar e pr√©-processar** o Seeds Dataset.
3. **Implementar e comparar** diferentes algoritmos de classifica√ß√£o:
   - K-Nearest Neighbors (KNN)  
   - Support Vector Machine (SVM)  
   - Random Forest  
   - Regress√£o Log√≠stica  
   - Naive Bayes  
4. **Otimizar** os modelos com **GridSearchCV**.
5. **Interpretar os resultados** e extrair insights relevantes, relacionando-os com o contexto real de cooperativas agr√≠colas.
6. Discutir **por que os resultados podem ser considerados confi√°veis**.

---

## üìÅ Dataset: Seeds (UCI Machine Learning Repository)

- Fonte: UCI Machine Learning Repository ‚Äì *Seeds Dataset*  
- N√∫mero de amostras: **210**  
- Classes (3 variedades de trigo, 70 amostras cada):
  - `1` ‚Üí **Kama**  
  - `2` ‚Üí **Rosa**  
  - `3` ‚Üí **Canadian**  

### üî¢ Atributos (features)

Cada amostra √© um gr√£o de trigo descrito por 7 caracter√≠sticas f√≠sicas, extra√≠das a partir do contorno do gr√£o:

1. **area** ‚Äì √Årea do gr√£o.
2. **perimeter** ‚Äì Comprimento do contorno do gr√£o.
3. **compactness** ‚Äì Compacidade:  
   \\( C = \frac{4 \pi A}{P^2} \\)  
   Mede o qu√£o ‚Äúcheio‚Äù/compacto √© o gr√£o. Valores menores indicam formatos mais alongados.
4. **kernel_length** ‚Äì Comprimento do n√∫cleo (eixo maior da elipse equivalente).
5. **kernel_width** ‚Äì Largura do n√∫cleo (eixo menor da elipse).
6. **asymmetry** ‚Äì Coeficiente de assimetria; mensura o quanto o gr√£o foge de um formato sim√©trico.
7. **groove_length** ‚Äì Comprimento do sulco do n√∫cleo (a ‚Äúmarquinha‚Äù central do gr√£o).
8. **class** / **class_name** ‚Äì Variedade de trigo (Kama, Rosa, Canadian).

O dataset √© **balanceado**: 70 amostras de cada classe.

---

## üß† Metodologia: CRISP-DM

O projeto foi estruturado seguindo as fases do **CRISP-DM**:

### 1. Entendimento do Neg√≥cio

- Problema: classifica√ß√£o manual de gr√£os de trigo ‚Üí lenta, subjetiva, mais cara.
- Objetivo: desenvolver um modelo de ML capaz de **classificar automaticamente** a variedade do gr√£o com boa acur√°cia, servindo como:
  - Apoio ao especialista;
  - Ferramenta para acelerar o fluxo de trabalho na cooperativa.

### 2. Entendimento dos Dados

Passos principais realizados:

- Leitura do dataset `seeds_dataset.txt` (sem cabe√ßalho, separado por espa√ßos).
- Nomea√ß√£o das colunas com base na documenta√ß√£o da UCI.
- An√°lises iniciais:
  - `df.head()`, `df.info()`, `df.describe()`;
  - Verifica√ß√£o de **valores ausentes** (n√£o h√° NaNs);
  - Distribui√ß√£o das classes (`class` e `class_name`) ‚Üí dataset balanceado.
- An√°lise explorat√≥ria:
  - Histogramas das 7 features;
  - Boxplots (para visualizar poss√≠veis outliers);
  - Matriz de correla√ß√£o;
  - Gr√°ficos de dispers√£o:
    - `area √ó perimeter`;
    - `kernel_length √ó kernel_width`;  
    coloridos pela classe.

**Principais observa√ß√µes:**

- Forte correla√ß√£o entre vari√°veis de ‚Äútamanho‚Äù (√°rea, per√≠metro, comprimento e sulco).
- Compactness e assimetria ajudam a capturar o **formato**, n√£o apenas o tamanho.
- As classes formam agrupamentos parcialmente separados no espa√ßo das features ‚Üí problema prop√≠cio √† classifica√ß√£o.

### 3. Prepara√ß√£o dos Dados

- Remo√ß√£o apenas das colunas de r√≥tulo para formar `X`:
  - `X` = todas as features num√©ricas (`area`, `perimeter`, ‚Ä¶, `groove_length`).
  - `y` = `class` (1, 2 ou 3).
- Divis√£o em **treino** e **teste**:
  - 70% treino, 30% teste;
  - `train_test_split(..., stratify=y, random_state=42)`  
    ‚Üí garante mesma propor√ß√£o de classes em treino e teste.
- Padroniza√ß√£o:
  - Uso de `StandardScaler` dentro de um **Pipeline** (`scikit-learn`);
  - Evita vazamento de informa√ß√£o (data leakage) e melhora desempenho de SVM e KNN.

### 4. Modelagem

Foram treinados 5 modelos:

- **K-Nearest Neighbors (KNN)**
- **Support Vector Machine (SVM)**
- **Random Forest**
- **Regress√£o Log√≠stica**
- **Naive Bayes**

Cada modelo foi treinado em um `Pipeline`:

```python
Pipeline([
    ("scaler", StandardScaler()),
    ("clf", <modelo>)
])
